# Adversarial-Image-Detection 
## Abstract

In recent researches, it has been shown that deep neural networks can  easily be fooled by adversarial examples. Since then researchers have proposed various adversarial attacks and defense  (either to make the neural network more robust or to detect the adversarial examples) techniques. In this paper we are proposing one novel method to detect the adversarial examples. We have built a detection framework in which collection of binary classifiers trained on edge representations of original data set detect adversarial examples from real inputs before the output of the classifier is taken seriously. Our approach gives encouraging results on state of the art attacks.

A short description of the research work can be found here: https://drive.google.com/open?id=1K4P4HgZ7UN6dkBFxd05USWAMtex3Qg7W
